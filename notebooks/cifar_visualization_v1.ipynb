{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7521f73b",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ebc15ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "227b3452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Transformations\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "# Load train set\n",
    "train_set = dsets.CIFAR10('../', train=True, download=True, transform=transform_train)\n",
    "\n",
    "# Load test set (using as validation)\n",
    "val_set = dsets.CIFAR10('../', train=False, download=True, transform=transform_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0af5dd2",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90259cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import os.path\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "from copy import deepcopy\n",
    "from resnet import ResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6aefaa9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select device\n",
    "# device = torch.device('cuda')\n",
    "device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27f9f2fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36m__pycache__\u001b[m\u001b[m                  cifar.ipynb\r\n",
      "census.ipynb                 cifar_visualization_v1.ipynb\r\n",
      "cifar explainer.pt           layers.py\r\n",
      "cifar resnet.pt              resnet.py\r\n",
      "cifar single model.ipynb     unet.py\r\n",
      "cifar surrogate.pt           vit.py\r\n",
      "cifar-vit.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7a6fe31b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(os.path.isfile('./cifar resnet.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8311f723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading saved model\n"
     ]
    }
   ],
   "source": [
    "# Check for model\n",
    "if os.path.isfile('cifar resnet.pt'):\n",
    "    # Load saved model\n",
    "    print('Loading saved model')\n",
    "    model = torch.load('cifar resnet.pt').to(device)\n",
    "\n",
    "else:\n",
    "    # Create model\n",
    "    model = ResNet18(num_classes=10).to(device)\n",
    "\n",
    "    # Training parameters\n",
    "    lr = 1e-3\n",
    "    mbsize = 256  # 16\n",
    "    max_nepochs = 250\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    lookback = 10\n",
    "    verbose = True\n",
    "\n",
    "    # Validation function\n",
    "    val_loader = DataLoader(val_set, batch_size=mbsize, shuffle=False, num_workers=4)\n",
    "\n",
    "    def validate(model):\n",
    "        n = 0\n",
    "        mean_loss = 0\n",
    "        mean_acc = 0\n",
    "\n",
    "        for x, y in val_loader:\n",
    "            # Move to GPU.\n",
    "            n += len(x)\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            # Get predictions.\n",
    "            pred = model(x)\n",
    "\n",
    "            # Update loss.\n",
    "            loss = loss_fn(pred, y).item()\n",
    "            mean_loss += len(x) * (loss - mean_loss) / n\n",
    "\n",
    "            # Update accuracy.\n",
    "            acc = (torch.argmax(pred, dim=1) == y).float().mean().item()\n",
    "            mean_acc += len(x) * (acc - mean_acc) / n\n",
    "\n",
    "        return mean_loss, mean_acc\n",
    "\n",
    "    # Data loader\n",
    "    train_loader = DataLoader(train_set, batch_size=mbsize, shuffle=True,\n",
    "                              drop_last=True, num_workers=4)\n",
    "\n",
    "    # Setup\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, factor=0.5, patience=lookback // 2, min_lr=1e-5,\n",
    "        mode='max', verbose=verbose)\n",
    "    loss_list = []\n",
    "    acc_list = []\n",
    "    min_criterion = np.inf\n",
    "    min_epoch = 0\n",
    "\n",
    "    # Train\n",
    "    for epoch in range(max_nepochs):\n",
    "        for x, y in tqdm(train_loader, desc='Training loop', leave=True):\n",
    "            # Move to device.\n",
    "            x = x.to(device=device)\n",
    "            y = y.to(device=device)\n",
    "\n",
    "            # Take gradient step.\n",
    "            loss = loss_fn(model(x), y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            model.zero_grad()\n",
    "\n",
    "        # Check progress.\n",
    "        with torch.no_grad():\n",
    "            # Calculate validation loss.\n",
    "            model.eval()\n",
    "            val_loss, val_acc = validate(model)\n",
    "            model.train()\n",
    "            if verbose:\n",
    "                print('----- Epoch = {} -----'.format(epoch + 1))\n",
    "                print('Val loss = {:.4f}'.format(val_loss))\n",
    "                print('Val acc = {:.4f}'.format(val_acc))\n",
    "            loss_list.append(val_loss)\n",
    "            acc_list.append(val_acc)\n",
    "            scheduler.step(val_acc)\n",
    "\n",
    "            # Check convergence criterion.\n",
    "            val_criterion = - val_acc\n",
    "            if val_criterion < min_criterion:\n",
    "                min_criterion = val_criterion\n",
    "                min_epoch = epoch\n",
    "                best_model = deepcopy(model)\n",
    "                print('')\n",
    "                print('New best epoch, acc = {:.4f}'.format(val_acc))\n",
    "                print('')\n",
    "            elif (epoch - min_epoch) == lookback:\n",
    "                if verbose:\n",
    "                    print('Stopping early')\n",
    "                break\n",
    "\n",
    "    # Keep best model\n",
    "    model = best_model\n",
    "    \n",
    "    # Save model\n",
    "    model.cpu()\n",
    "    torch.save(model, 'cifar resnet.pt')\n",
    "    model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f716735",
   "metadata": {},
   "source": [
    "# Train surrogate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e143a345",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastshap import ImageSurrogate\n",
    "from fastshap.utils import MaskLayer2d, KLDivLoss, DatasetInputOnly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86272b90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(os.path.isfile('cifar surrogate.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "873b3ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading saved surrogate model\n"
     ]
    }
   ],
   "source": [
    "# Check for model\n",
    "if os.path.isfile('cifar surrogate.pt'):\n",
    "    print('Loading saved surrogate model')\n",
    "    surr = torch.load('cifar surrogate.pt').to(device)\n",
    "    surrogate = ImageSurrogate(surr, width=32, height=32, superpixel_size=2)\n",
    "\n",
    "else:\n",
    "    # Create model\n",
    "    surr = nn.Sequential(\n",
    "        MaskLayer2d(value=0, append=True),\n",
    "        ResNet18(in_channels=4, num_classes=10)).to(device)\n",
    "\n",
    "    # Set up surrogate object\n",
    "    surrogate = ImageSurrogate(surr, width=32, height=32, superpixel_size=2)\n",
    "    \n",
    "    # Set up datasets\n",
    "    train_surr = DatasetInputOnly(train_set)\n",
    "    val_surr = DatasetInputOnly(val_set)\n",
    "    original_model = nn.Sequential(model, nn.Softmax(dim=1))\n",
    "\n",
    "    # Train\n",
    "    surrogate.train_original_model(\n",
    "        train_surr,\n",
    "        val_surr,\n",
    "        original_model,\n",
    "        batch_size=256,\n",
    "        max_epochs=100,\n",
    "        loss_fn=KLDivLoss(),\n",
    "        lookback=10,\n",
    "        bar=True,\n",
    "        verbose=True)\n",
    "    \n",
    "    # Save surrogate\n",
    "    surr.cpu()\n",
    "    torch.save(surr, 'cifar surrogate.pt')\n",
    "    surr.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114dc86f",
   "metadata": {},
   "source": [
    "# Train FastSHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca5f640f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unet import UNet\n",
    "from fastshap import FastSHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea06ffb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(os.path.isfile('cifar explainer.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71acd881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading saved explainer model\n"
     ]
    }
   ],
   "source": [
    "# Check for model\n",
    "if os.path.isfile('cifar explainer.pt'):\n",
    "    print('Loading saved explainer model')\n",
    "    explainer = torch.load('cifar explainer.pt').to(device)\n",
    "    fastshap = FastSHAP(explainer, surrogate, link=nn.LogSoftmax(dim=1))\n",
    "\n",
    "else:\n",
    "    # Set up explainer model\n",
    "    explainer = UNet(n_classes=10, num_down=2, num_up=1, num_convs=3).to(device)\n",
    "\n",
    "    # Set up FastSHAP object\n",
    "    fastshap = FastSHAP(explainer, surrogate, link=nn.LogSoftmax(dim=1))\n",
    "\n",
    "    # Set up datasets\n",
    "    fastshap_train = DatasetInputOnly(train_set)\n",
    "    fastshap_val = DatasetInputOnly(val_set)\n",
    "\n",
    "    # Train\n",
    "    fastshap.train(\n",
    "        fastshap_train,\n",
    "        fastshap_val,\n",
    "        batch_size=128,\n",
    "        num_samples=2,\n",
    "        max_epochs=200,\n",
    "        eff_lambda=1e-2,\n",
    "        validation_samples=1,\n",
    "        lookback=10,\n",
    "        bar=True,\n",
    "        verbose=True)\n",
    "    \n",
    "    # Save explainer\n",
    "    explainer.cpu()\n",
    "    torch.save(explainer, 'cifar explainer.pt')\n",
    "    explainer.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5702ef",
   "metadata": {},
   "source": [
    "# Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7256a02d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.5.1-cp39-cp39-macosx_10_9_x86_64.whl (7.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 7.3 MB 4.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pillow>=6.2.0 in /opt/anaconda3/envs/ml_project_v2/lib/python3.9/site-packages (from matplotlib) (9.1.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/envs/ml_project_v2/lib/python3.9/site-packages (from matplotlib) (1.22.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/envs/ml_project_v2/lib/python3.9/site-packages (from matplotlib) (21.3)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.4.2-cp39-cp39-macosx_10_9_x86_64.whl (65 kB)\n",
      "\u001b[K     |████████████████████████████████| 65 kB 7.6 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7 in /opt/anaconda3/envs/ml_project_v2/lib/python3.9/site-packages (from matplotlib) (2.8.2)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.33.3-py3-none-any.whl (930 kB)\n",
      "\u001b[K     |████████████████████████████████| 930 kB 20.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cycler>=0.10\n",
      "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/anaconda3/envs/ml_project_v2/lib/python3.9/site-packages (from matplotlib) (3.0.4)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/envs/ml_project_v2/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Installing collected packages: kiwisolver, fonttools, cycler, matplotlib\n",
      "Successfully installed cycler-0.11.0 fonttools-4.33.3 kiwisolver-1.4.2 matplotlib-3.5.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3270598",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/f8/lhp_w5d54gx1xxj3dqbx7yqr0000gn/T/ipykernel_16285/322768712.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "72b94e21",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Upsample' object has no attribute 'recompute_scale_factor'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [26]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(x)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Get explanations\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[43mfastshap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshap_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Get predictions\u001b[39;00m\n\u001b[1;32m     14\u001b[0m pred \u001b[38;5;241m=\u001b[39m surrogate(\n\u001b[1;32m     15\u001b[0m     x\u001b[38;5;241m.\u001b[39mto(device),\n\u001b[1;32m     16\u001b[0m     torch\u001b[38;5;241m.\u001b[39mones(num_classes, surrogate\u001b[38;5;241m.\u001b[39mnum_players, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m     17\u001b[0m )\u001b[38;5;241m.\u001b[39msoftmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ml_project_v2/lib/python3.9/site-packages/fastshap/fastshap.py:478\u001b[0m, in \u001b[0;36mFastSHAP.shap_values\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    476\u001b[0m     \u001b[38;5;66;03m# Evaluate explainer.\u001b[39;00m\n\u001b[1;32m    477\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m--> 478\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_explainer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalization\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnull\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimputer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_players\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minference\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m pred\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ml_project_v2/lib/python3.9/site-packages/fastshap/fastshap.py:55\u001b[0m, in \u001b[0;36mevaluate_explainer\u001b[0;34m(explainer, normalization, x, grand, null, num_players, inference)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;124;03mHelper function for evaluating the explainer model and performing necessary\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;124;03mnormalization and reshaping operations.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;124;03m  inference: whether this is inference time (or training).\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# Evaluate explainer.\u001b[39;00m\n\u001b[0;32m---> 55\u001b[0m pred \u001b[38;5;241m=\u001b[39m \u001b[43mexplainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# Reshape SHAP values.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(pred\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m4\u001b[39m:\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;66;03m# Image.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ml_project_v2/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/nyu/ml/project_main/ml_project/notebooks/unet.py:187\u001b[0m, in \u001b[0;36mUNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, up \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mup_layers):\n\u001b[1;32m    186\u001b[0m     residual_x \u001b[38;5;241m=\u001b[39m x_list[\u001b[38;5;241m-\u001b[39m(i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2\u001b[39m)]\n\u001b[0;32m--> 187\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresidual_x\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;66;03m# Output.\u001b[39;00m\n\u001b[1;32m    190\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutc(x)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ml_project_v2/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/nyu/ml/project_main/ml_project/notebooks/unet.py:102\u001b[0m, in \u001b[0;36mUp.forward\u001b[0;34m(self, x1, x2)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x1, x2):\n\u001b[0;32m--> 102\u001b[0m     x1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;66;03m# input is CHW\u001b[39;00m\n\u001b[1;32m    104\u001b[0m     diffY \u001b[38;5;241m=\u001b[39m x2\u001b[38;5;241m.\u001b[39msize()[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m-\u001b[39m x1\u001b[38;5;241m.\u001b[39msize()[\u001b[38;5;241m2\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ml_project_v2/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ml_project_v2/lib/python3.9/site-packages/torch/nn/modules/upsampling.py:154\u001b[0m, in \u001b[0;36mUpsample.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39minterpolate(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale_factor, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malign_corners,\n\u001b[0;32m--> 154\u001b[0m                          recompute_scale_factor\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecompute_scale_factor\u001b[49m)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/ml_project_v2/lib/python3.9/site-packages/torch/nn/modules/module.py:1185\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1183\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1185\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1186\u001b[0m     \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, name))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Upsample' object has no attribute 'recompute_scale_factor'"
     ]
    }
   ],
   "source": [
    "# Select one image from each class\n",
    "dset = val_set\n",
    "targets = np.array(dset.targets)\n",
    "num_classes = targets.max() + 1\n",
    "inds_lists = [np.where(targets == cat)[0] for cat in range(num_classes)]\n",
    "inds = [np.random.choice(cat_inds) for cat_inds in inds_lists]\n",
    "x, y = zip(*[dset[ind] for ind in inds])\n",
    "x = torch.stack(x)\n",
    "\n",
    "# Get explanations\n",
    "values = fastshap.shap_values(x.to(device))\n",
    "\n",
    "# Get predictions\n",
    "pred = surrogate(\n",
    "    x.to(device),\n",
    "    torch.ones(num_classes, surrogate.num_players, device=device)\n",
    ").softmax(dim=1).cpu().data.numpy()\n",
    "\n",
    "fig, axarr = plt.subplots(num_classes, num_classes + 1, figsize=(22, 20))\n",
    "\n",
    "for row in range(num_classes):\n",
    "    # Image\n",
    "    classes = ['Airplane', 'Car', 'Bird', 'Cat', 'Deer', 'Dog', 'Frog', 'Horse', 'Ship', 'Truck']\n",
    "    mean = np.array([0.4914, 0.4822, 0.4465])[:, np.newaxis, np.newaxis]\n",
    "    std = np.array([0.2023, 0.1994, 0.2010])[:, np.newaxis, np.newaxis]\n",
    "    im = x[row].numpy() * std + mean\n",
    "    im = im.transpose(1, 2, 0).astype(float)\n",
    "    im = np.clip(im, a_min=0, a_max=1)\n",
    "    axarr[row, 0].imshow(im, vmin=0, vmax=1)\n",
    "    axarr[row, 0].set_xticks([])\n",
    "    axarr[row, 0].set_yticks([])\n",
    "    axarr[row, 0].set_ylabel('{}'.format(classes[y[row]]), fontsize=14)\n",
    "    \n",
    "    # Explanations\n",
    "    m = np.abs(values[row]).max()\n",
    "    for col in range(num_classes):\n",
    "        axarr[row, col + 1].imshow(values[row, col], cmap='seismic', vmin=-m, vmax=m)\n",
    "        axarr[row, col + 1].set_xticks([])\n",
    "        axarr[row, col + 1].set_yticks([])\n",
    "        if col == y[row]:\n",
    "            axarr[row, col + 1].set_xlabel('{:.2f}'.format(pred[row, col]), fontsize=12, fontweight='bold')\n",
    "        else:\n",
    "            axarr[row, col + 1].set_xlabel('{:.2f}'.format(pred[row, col]), fontsize=12)\n",
    "        \n",
    "        # Class labels\n",
    "        if row == 0:\n",
    "            axarr[row, col + 1].set_title('{}'.format(classes[y[col]]), fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b623d46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
